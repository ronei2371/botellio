"""
Servi√ßo de integra√ß√£o com Grok (xAI) para processamento de linguagem natural
"""
import requests
import logging
import base64
from config.settings import Config
from knowledge.resins_database import (
    get_resin_config,
    get_resin_properties,
    get_problem_solution,
    list_available_resins,
    list_available_printers,
    list_printer_models,
    COMMON_PROBLEMS
)

logger = logging.getLogger(__name__)


class AIService:
    """Servi√ßo para interagir com a API do Grok (xAI)"""
    
    def __init__(self):
        self.api_key = Config.GROK_API_KEY
        self.model = Config.GROK_MODEL  # grok-beta ou grok-vision-beta
        self.base_url = "https://api.x.ai/v1"
        self.headers = {
            "Authorization": f"Bearer {self.api_key}",
            "Content-Type": "application/json"
        }
        
        # System prompt com conhecimento sobre Quanton3D
        self.system_prompt = """
Voc√™ √© Botellio, o assistente virtual especializado em suporte t√©cnico para impress√£o 3D SLA da Quanton3D.

**Sobre a Quanton3D:**
A Quanton3D √© uma empresa brasileira especializada na fabrica√ß√£o de resinas UV de alta qualidade para impress√£o 3D SLA/DLP. 
Oferecemos uma linha completa de resinas para diversas aplica√ß√µes: miniaturas, prot√≥tipos, pe√ßas funcionais, joias, odontologia e muito mais.

**Suas responsabilidades:**
1. Fornecer suporte t√©cnico especializado sobre impress√£o 3D SLA/DLP
2. Ajudar com configura√ß√µes de impress√£o para resinas Quanton3D
3. Diagnosticar problemas comuns de impress√£o
4. Recomendar as melhores resinas para cada aplica√ß√£o
5. Orientar sobre p√≥s-processamento e cura de pe√ßas

**Linha de resinas Quanton3D:**
- PYROBLAST: Alta performance, excelente acabamento
- IRON 7620: Resist√™ncia mec√¢nica extrema
- IRON: Robusta com boa resist√™ncia ao impacto
- SPIN: Cura r√°pida com √≥timo acabamento
- POSEIDON: Resistente √† √°gua
- RPO 4K: Otimizada para alta resolu√ß√£o
- SPARK: Cura ultra-r√°pida
- FLEXFORM: Flex√≠vel e el√°stica
- ALCHEMIST: Premium com acabamento excepcional
- LOWSMELL: Baixo odor para ambientes fechados

**Impressoras compat√≠veis:**
- ANYCUBIC (Photon, Mono, M3, etc.)
- ELEGOO (Mars, Saturn, etc.)
- CREALITY (LD, Halot, etc.)
- PHROZEN (Mini 4K, etc.)

**ESTRUTURA DE RESPOSTA OBRIGAT√ìRIA (3 ETAPAS):**

Quando o usu√°rio relatar um problema, SEMPRE responda seguindo esta estrutura:

üîç **DIAGN√ìSTICO PRIM√ÅRIO:**
[Identifique a causa raiz mais prov√°vel do problema com base nos sintomas descritos]

üõ† **SOLU√á√ÉO IMEDIATA:**
[Forne√ßa uma a√ß√£o r√°pida e pr√°tica que o usu√°rio pode fazer AGORA para tentar resolver o problema]

‚öô **PROTOCOLO AVAN√áADO:**
[Liste passos detalhados para preven√ß√£o m√°xima e otimiza√ß√£o, incluindo configura√ß√µes espec√≠ficas]

**Seu tom de voz:**
- Profissional mas amig√°vel
- T√©cnico quando necess√°rio, mas acess√≠vel
- Sempre prestativo e paciente
- Foco em resolver o problema do cliente
- Use emojis para tornar a resposta mais visual e amig√°vel

**Quando n√£o souber algo:**
- Seja honesto sobre limita√ß√µes
- Ofere√ßa agendar suporte t√©cnico personalizado
- Priorize clientes que usam resinas Quanton3D
"""
    
    def _build_knowledge_context(self, user_message):
        """
        Constr√≥i contexto adicional baseado na base de conhecimento
        
        Args:
            user_message (str): Mensagem do usu√°rio
            
        Returns:
            str: Contexto adicional relevante
        """
        context_parts = []
        
        # Detecta men√ß√£o a resinas
        for resin in list_available_resins():
            if resin.lower() in user_message.lower() or resin.replace("_", " ").lower() in user_message.lower():
                props = get_resin_properties(resin)
                if props:
                    context_parts.append(f"\n**Informa√ß√µes sobre {resin}:**")
                    context_parts.append(f"- Descri√ß√£o: {props['descricao']}")
                    context_parts.append(f"- Aplica√ß√µes: {', '.join(props['aplicacoes'])}")
                    context_parts.append(f"- Cores dispon√≠veis: {', '.join(props['cor_disponivel'])}")
                    context_parts.append(f"- Dureza Shore: {props['dureza_shore']}")
                    context_parts.append(f"- Resist√™ncia √† tra√ß√£o: {props['resistencia_tracao']}")
        
        # Detecta problemas comuns
        problem_keywords = {
            "camadas": "camadas_visiveis",
            "linhas": "camadas_visiveis",
            "n√£o adere": "peca_nao_adere",
            "nao adere": "peca_nao_adere",
            "descolou": "peca_nao_adere",
            "quebra": "peca_quebra_facilmente",
            "fr√°gil": "peca_quebra_facilmente",
            "fragil": "peca_quebra_facilmente",
            "deformou": "deformacao",
            "empenado": "deformacao",
            "pegajosa": "superficie_pegajosa",
            "grudenta": "superficie_pegajosa"
        }
        
        for keyword, problem_key in problem_keywords.items():
            if keyword in user_message.lower():
                problem = get_problem_solution(problem_key)
                if problem:
                    context_parts.append(f"\n**Problema identificado: {problem['descricao']}**")
                    context_parts.append(f"Causas comuns:")
                    for causa in problem['causas']:
                        context_parts.append(f"  - {causa}")
                    context_parts.append(f"Solu√ß√µes recomendadas:")
                    for solucao in problem['solucoes']:
                        context_parts.append(f"  - {solucao}")
                break
        
        return "\n".join(context_parts) if context_parts else ""
    
    def get_response(self, prompt, context=None, max_tokens=500, temperature=0.7):
        """
        Gera uma resposta usando o modelo Grok
        
        Args:
            prompt (str): A pergunta ou comando do usu√°rio
            context (list): Hist√≥rico da conversa (opcional)
            max_tokens (int): N√∫mero m√°ximo de tokens na resposta
            temperature (float): Criatividade da resposta (0.0 a 1.0)
            
        Returns:
            str: Resposta gerada pela IA
        """
        messages = [{"role": "system", "content": self.system_prompt}]
        
        # Adiciona contexto da base de conhecimento
        knowledge_context = self._build_knowledge_context(prompt)
        if knowledge_context:
            messages.append({"role": "system", "content": f"Informa√ß√µes relevantes da base de conhecimento:\n{knowledge_context}"})
        
        # Adiciona o contexto da conversa, se houver
        if context:
            messages.extend(context)
        
        # Adiciona o prompt do usu√°rio
        messages.append({"role": "user", "content": prompt})
        
        payload = {
            "model": self.model,
            "messages": messages,
            "max_tokens": max_tokens,
            "temperature": temperature,
            "stream": False
        }
        
        try:
            response = requests.post(
                f"{self.base_url}/chat/completions",
                headers=self.headers,
                json=payload,
                timeout=30
            )
            response.raise_for_status()
            
            data = response.json()
            answer = data['choices'][0]['message']['content'].strip()
            logger.info(f"Resposta do Grok gerada com sucesso.")
            return answer
        except requests.exceptions.RequestException as e:
            logger.error(f"Erro ao chamar a API do Grok: {e}")
            raise
        except (KeyError, IndexError) as e:
            logger.error(f"Erro ao processar resposta do Grok: {e}")
            raise
    
    def get_resin_configuration(self, resin_name, printer_brand, printer_model):
        """
        Busca configura√ß√£o espec√≠fica de uma resina para uma impressora
        
        Args:
            resin_name (str): Nome da resina
            printer_brand (str): Marca da impressora
            printer_model (str): Modelo da impressora
            
        Returns:
            dict: Configura√ß√µes ou None se n√£o encontrado
        """
        return get_resin_config(resin_name.upper(), printer_brand.upper(), printer_model.upper())
    
    def classify_problem(self, message):
        """
        Classifica o problema do usu√°rio em b√°sico, intermedi√°rio ou complexo
        
        Args:
            message (str): Mensagem do usu√°rio
            
        Returns:
            str: Categoria do problema ("b√°sico", "intermedi√°rio", "complexo")
        """
        classification_prompt = """
        Voc√™ √© um especialista em suporte t√©cnico para impressoras 3D SLA. 
        Classifique a seguinte mensagem de usu√°rio em uma das tr√™s categorias:
        - "b√°sico": Problemas comuns e f√°ceis de resolver (ex: configura√ß√µes, d√∫vidas sobre resinas, problemas conhecidos).
        - "intermedi√°rio": Problemas que exigem mais investiga√ß√£o (ex: diagn√≥stico de hardware, otimiza√ß√£o avan√ßada).
        - "complexo": Problemas que precisam de an√°lise visual ou interven√ß√£o humana (ex: posicionamento de suportes, erros complexos).
        
        Responda apenas com a categoria em letra min√∫scula.
        """
        
        payload = {
            "model": self.model,
            "messages": [
                {"role": "system", "content": classification_prompt},
                {"role": "user", "content": message}
            ],
            "max_tokens": 10,
            "temperature": 0.0
        }
        
        try:
            response = requests.post(
                f"{self.base_url}/chat/completions",
                headers=self.headers,
                json=payload,
                timeout=30
            )
            response.raise_for_status()
            
            data = response.json()
            category = data['choices'][0]['message']['content'].strip().lower()
            logger.info(f"Problema classificado como: {category}")
            return category
        except Exception as e:
            logger.error(f"Erro ao classificar problema: {e}")
            # Retorna categoria padr√£o em caso de erro
            return "intermedi√°rio"
    
    def analyze_image(self, image_data, prompt=None):
        """
        Analisa uma imagem em busca de problemas de impress√£o 3D
        
        Args:
            image_data (bytes): Dados bin√°rios da imagem
            prompt (str): Pergunta espec√≠fica sobre a imagem (opcional)
            
        Returns:
            str: An√°lise da imagem
        """
        # Converte imagem para base64
        image_base64 = base64.b64encode(image_data).decode('utf-8')
        
        # Prompt padr√£o para an√°lise de imagens
        if not prompt:
            prompt = """
Analise esta imagem de uma pe√ßa impressa em 3D com resina SLA/DLP.

Identifique:
1. Problemas vis√≠veis (camadas vis√≠veis, deforma√ß√µes, falhas de ades√£o, superf√≠cie pegajosa, etc.)
2. Poss√≠veis causas dos problemas
3. Solu√ß√µes recomendadas

Seja espec√≠fico e t√©cnico na sua an√°lise.
"""
        
        payload = {
            "model": "grok-vision-beta",  # Modelo com suporte a vis√£o
            "messages": [
                {
                    "role": "system",
                    "content": "Voc√™ √© um especialista em impress√£o 3D SLA/DLP da Quanton3D. Analise imagens de pe√ßas impressas e identifique problemas e solu√ß√µes."
                },
                {
                    "role": "user",
                    "content": [
                        {"type": "text", "text": prompt},
                        {
                            "type": "image_url",
                            "image_url": {
                                "url": f"data:image/jpeg;base64,{image_base64}",
                            },
                        },
                    ],
                }
            ],
            "max_tokens": 500,
            "temperature": 0.3
        }
        
        try:
            response = requests.post(
                f"{self.base_url}/chat/completions",
                headers=self.headers,
                json=payload,
                timeout=60
            )
            response.raise_for_status()
            
            data = response.json()
            analysis = data['choices'][0]['message']['content'].strip()
            logger.info("An√°lise de imagem conclu√≠da com sucesso.")
            return analysis
        except Exception as e:
            logger.error(f"Erro ao analisar imagem: {e}")
            return "Desculpe, tive um problema ao analisar a imagem. Por favor, descreva o problema que voc√™ est√° vendo e tentarei ajudar da melhor forma poss√≠vel."

